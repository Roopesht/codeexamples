{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Sentiment Analyzer\n",
    "\n",
    "This notebook demonstrates a simple sentiment analysis pipeline with TF-IDF and Logistic Regression.\n",
    "It includes preprocessing, training, evaluation, and prediction on new examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SentimentAnalyzer Class\n",
    "\n",
    "This class handles preprocessing, training, evaluation, and prediction. It also prints detailed metrics and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1,2))\n",
    "        self.classifier = LogisticRegression(max_iter=1000)\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^a-z\\s]', '', text)\n",
    "        return text.strip()\n",
    "\n",
    "    def train(self, texts, labels):\n",
    "        clean_texts = [self.preprocess_text(t) for t in texts]\n",
    "        X = self.vectorizer.fit_transform(clean_texts)\n",
    "        self.classifier.fit(X, labels)\n",
    "\n",
    "    def evaluate(self, test_texts, test_labels):\n",
    "        clean_texts = [self.preprocess_text(t) for t in test_texts]\n",
    "        X_test = self.vectorizer.transform(clean_texts)\n",
    "        y_pred = self.classifier.predict(X_test)\n",
    "\n",
    "        print(\"Confusion matrix:\\n\", confusion_matrix(test_labels, y_pred))\n",
    "        print(\"\\nClassification report:\\n\", classification_report(test_labels, y_pred, zero_division=0))\n",
    "\n",
    "        accuracy = accuracy_score(test_labels, y_pred)\n",
    "        precision = precision_score(test_labels, y_pred, zero_division=0)\n",
    "        recall = recall_score(test_labels, y_pred, zero_division=0)\n",
    "        f1 = f1_score(test_labels, y_pred, zero_division=0)\n",
    "\n",
    "        print(f\"Accuracy:  {accuracy:.2f}\")\n",
    "        print(f\"Precision: {precision:.2f}\")\n",
    "        print(f\"Recall:    {recall:.2f}\")\n",
    "        print(f\"F1-Score:  {f1:.2f}\")\n",
    "\n",
    "    def predict(self, text):\n",
    "        text = self.preprocess_text(text)\n",
    "        X = self.vectorizer.transform([text])\n",
    "        pred = self.classifier.predict(X)[0]\n",
    "        proba = self.classifier.predict_proba(X).max()\n",
    "        label = 'Positive' if pred == 1 else 'Negative'\n",
    "        return label, float(proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo Dataset\n",
    "A small IMDB-like dataset to simulate sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"I loved this movie! It was fantastic.\",\n",
    "    \"An excellent film with great performances.\",\n",
    "    \"The movie was boring and too long.\",\n",
    "    \"I hated this film. Terrible acting!\",\n",
    "    \"Good story but weak direction.\",\n",
    "    \"Absolutely amazing experience!\",\n",
    "    \"Not worth watching again.\",\n",
    "    \"It was okay, not bad but not great either.\"\n",
    "]\n",
    "labels = [1, 1, 0, 0, 0, 1, 0, 0]\n",
    "\n",
    "# Train/test split with stratify\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    texts, labels, test_size=0.25, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "print(\"Train labels distribution:\", train_labels)\n",
    "print(\"Test labels distribution: \", test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentAnalyzer()\n",
    "analyzer.train(train_texts, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ“Š Model Evaluation:\")\n",
    "analyzer.evaluate(test_texts, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict New Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    \"This was a masterpiece!\",\n",
    "    \"I regret watching this.\",\n",
    "    \"Not a good film, sadly.\"\n",
    "]\n",
    "\n",
    "print(\"\\nðŸŽ­ Try New Reviews:\")\n",
    "for example in examples:\n",
    "    label, conf = analyzer.predict(example)\n",
    "    print(f\"'{example}' â†’ {label} (confidence: {conf:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- Small dataset = unstable metrics; use a larger dataset for real results.\n",
    "- TF-IDF with n-grams helps detect short phrases like 'not good'.\n",
    "- Confusion matrix and classification report help diagnose issues.\n",
    "- This structure can scale to thousands of reviews and more advanced preprocessing."
   ]
  }
 ]
}
