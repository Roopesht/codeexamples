{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîÑ Step-by-Step Flow\n",
    "\n",
    "1. üîç **Load & Explore:** Import IMDB dataset\n",
    "2. üßπ **Preprocess:** Clean and prepare text\n",
    "3. üî¢ **Vectorize:** Convert text to TF-IDF features\n",
    "4. ‚úÇÔ∏è **Split:** Train/test split (80/20)\n",
    "5. ü§ñ **Train:** Fit Logistic Regression model\n",
    "6. üéØ **Evaluate:** Test performance metrics\n",
    "7. üé≠ **Predict:** Try with new reviews\n",
    "\n",
    "We'll use scikit-learn and a small text dataset to simulate IMDB sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (uncomment if needed)\n",
    "# !pip install scikit-learn pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import re\n",
    "\n",
    "class SentimentAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "        self.classifier = LogisticRegression(max_iter=200)\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^a-z\\s]', '', text)\n",
    "        return text.strip()\n",
    "\n",
    "    def train(self, texts, labels):\n",
    "        clean_texts = [self.preprocess_text(t) for t in texts]\n",
    "        X = self.vectorizer.fit_transform(clean_texts)\n",
    "        self.classifier.fit(X, labels)\n",
    "\n",
    "    def evaluate(self, test_texts, test_labels):\n",
    "        clean_texts = [self.preprocess_text(t) for t in test_texts]\n",
    "        X_test = self.vectorizer.transform(clean_texts)\n",
    "        y_pred = self.classifier.predict(X_test)\n",
    "\n",
    "        accuracy = accuracy_score(test_labels, y_pred)\n",
    "        precision = precision_score(test_labels, y_pred)\n",
    "        recall = recall_score(test_labels, y_pred)\n",
    "        f1 = f1_score(test_labels, y_pred)\n",
    "\n",
    "        print(f\"Accuracy:  {accuracy:.2f}\")\n",
    "        print(f\"Precision: {precision:.2f}\")\n",
    "        print(f\"Recall:    {recall:.2f}\")\n",
    "        print(f\"F1-Score:  {f1:.2f}\")\n",
    "\n",
    "    def predict(self, text):\n",
    "        text = self.preprocess_text(text)\n",
    "        X = self.vectorizer.transform([text])\n",
    "        pred = self.classifier.predict(X)[0]\n",
    "        label = 'Positive' if pred == 1 else 'Negative'\n",
    "        return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß™ Let's Try It Out\n",
    "We'll train with a mini dataset and test predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample IMDB-like dataset\n",
    "texts = [\n",
    "    \"I loved this movie! It was fantastic.\",\n",
    "    \"An excellent film with great performances.\",\n",
    "    \"The movie was boring and too long.\",\n",
    "    \"I hated this film. Terrible acting!\",\n",
    "    \"Good story but weak direction.\",\n",
    "    \"Absolutely amazing experience!\",\n",
    "    \"Not worth watching again.\",\n",
    "    \"It was okay, not bad but not great either.\"\n",
    "]\n",
    "labels = [1, 1, 0, 0, 0, 1, 0, 0]\n",
    "\n",
    "# Train/test split\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize and train model\n",
    "analyzer = SentimentAnalyzer()\n",
    "analyzer.train(train_texts, train_labels)\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\nüìä Model Evaluation:\")\n",
    "analyzer.evaluate(test_texts, test_labels)\n",
    "\n",
    "# Predict new examples\n",
    "print(\"\\nüé≠ Try New Reviews:\")\n",
    "print(\"'This was a masterpiece!' ‚Üí\", analyzer.predict(\"This was a masterpiece!\"))\n",
    "print(\"'I regret watching this.' ‚Üí\", analyzer.predict(\"I regret watching this.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß† What We Did\n",
    "- Used **TF-IDF** to convert text into numerical features.\n",
    "- Trained a **Logistic Regression** model.\n",
    "- Evaluated the model using **accuracy**, **precision**, **recall**, and **F1-score**.\n",
    "- Tested it on **new unseen reviews**.\n",
    "\n",
    "This simple structure can be expanded using larger datasets, pipelines, and better preprocessing techniques."
   ]
  }
 ]
}
