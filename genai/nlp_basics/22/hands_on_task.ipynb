{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Entity Extractor Tool\n",
        "Welcome to this beginner-friendly tutorial on building an Entity Extractor Tool using Python and spaCy.\n",
        "In this notebook, we'll learn how to identify and visualize entities such as people, organizations, and places from text.\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup: Installing spaCy and Downloading the Model\n",
        "First, we need to install spaCy, a powerful NLP library, and download its English model.\n",
        "\n",
        "You can do this in your environment by running:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Import Required Libraries\n",
        "Let's import spaCy and other helpful modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "import json\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Building the Entity Extractor Class\n",
        "We'll create a class to process text, extract entities, visualize them, summarize, and save results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class EntityExtractor:\n",
        "    def __init__(self):\n",
        "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "    def extract_entities(self, text):\n",
        "        \"\"\"Process text to extract named entities.\"\"\"\n",
        "        doc = self.nlp(text)\n",
        "        entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "        return entities, doc\n",
        "\n",
        "    def visualize_entities(self, doc):\n",
        "        \"\"\"Create an interactive visualization of entities.\"\"\"\n",
        "        displacy.render(doc, style='ent', jupyter=True)\n",
        "\n",
        "    def get_summary(self, entities):\n",
        "        \"\"\"Count entities by type.\"\"\"\n",
        "        entity_types = [label for _, label in entities]\n",
        "        counts = Counter(entity_types)\n",
        "        return counts\n",
        "\n",
        "    def export_results(self, entities, filename):\n",
        "        \"\"\"Save entities and counts to a JSON file.\"\"\"\n",
        "        results = {\n",
        "            \"entities\": [{'text': text, 'label': label} for text, label in entities],\n",
        "            \"summary\": self.get_summary(entities)\n",
        "        }\n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(results, f, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Using the EntityExtractor\n",
        "Now, let's try processing some sample text and see the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Create an instance of the extractor\n",
        "extractor = EntityExtractor()\n",
        "\n",
        "# Sample user input\n",
        "user_input = \"Microsoft CEO Satya Nadella announced the opening of a new office in London. The hiring will focus on AI researchers from Stanford and MIT.\"\n",
        "\n",
        "# Extract entities\n",
        "entities, doc = extractor.extract_entities(user_input)\n",
        "\n",
        "# Visualize entities\n",
        "extractor.visualize_entities(doc)\n",
        "\n",
        "# Get summary counts\n",
        "summary = extractor.get_summary(entities)\n",
        "print(\"Entities found:\")\n",
        "for text, label in entities:\n",
        "    print(f\"{text} ({label})\")\n",
        "print(\"\\nSummary:\")\n",
        "print(summary)\n",
        "\n",
        "# Export results to JSON\n",
        "extractor.export_results(entities, 'entity_results.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Summary\n",
        "In this notebook, you've learned how to:\n",
        "- Install and load spaCy\n",
        "- Build an EntityExtractor class for processing text\n",
        "- Visualize entities with displacy\n",
        "- Generate summaries of entity counts\n",
        "- Save extracted data into a JSON file\n",
        "\n",
        "This is the foundation for building more advanced NLP tools! Keep experimenting with different texts and entity types."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}