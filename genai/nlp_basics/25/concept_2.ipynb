{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Understanding Transformer Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Welcome! In this notebook, we'll explore the basics of the Transformer architecture, a revolutionary model in AI and NLP.\n",
        " \n",
        "Let's start with an overview and some simple code to see how attention works!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèóÔ∏è Concept 2: Transformer Architecture Overview\n",
        "*The revolutionary design that changed everything*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The Transformer Solution\n",
        "Imagine having a bird's eye view of the entire sentence at once! Instead of reading word by word, transformers look at all words simultaneously, allowing for powerful understanding.\n",
        "- üëÅÔ∏è **Global attention:** See all words at the same time\n",
        "- ‚ö° **Parallel processing:** Handle all words at once\n",
        "- üéØ **Direct connections:** Any word can directly connect to any other word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Encoder-Decoder Architecture\n",
        "Transformers are built with two main parts:\n",
        "### üîç Encoder\n",
        "- Understands the input sequence\n",
        "- Uses multi-head attention, feed-forward networks, and layer normalization\n",
        "### üéØ Decoder\n",
        "- Generates the output sequence\n",
        "- Uses masked self-attention, cross-attention to the encoder, and feed-forward networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The Attention Revolution\n",
        "Here's a diagram showing how attention works:\n",
        "![Attention Mechanism Diagram](images/attention_mechanism.png)\n",
        "**Key Innovation:** Every word can directly \"attend\" to every other word!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Real-World Example: Language Translation\n",
        "- English: \"The cat that chased the mouse is sleeping\"\n",
        "- French: \"Le chat qui a chass√© la souris dort\"\n",
        "- üéØ \"cat\" directly connects to \"Le chat\"\n",
        "- üéØ \"sleeping\" directly connects to \"dort\"\n",
        "- ‚úÖ **No information loss!** Perfect long-range dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Demo: Transformer vs RNN Comparison\n",
        "Let's visualize how transformers process sequences differently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Simplified transformer attention concept\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def simple_attention(query, key, value):\n",
        "    \"\"\"Simplified self-attention mechanism\"\"\"\n",
        "    # Calculate attention scores\n",
        "    scores = torch.matmul(query, key.transpose(-2, -1))\n",
        "    # Apply softmax to get attention weights\n",
        "    attention_weights = F.softmax(scores, dim=-1)\n",
        "    # Apply attention to values\n",
        "    output = torch.matmul(attention_weights, value)\n",
        "    return output, attention_weights\n",
        "\n",
        "# Example usage\n",
        "sequence_length, embedding_dim = 5, 4\n",
        "x = torch.randn(sequence_length, embedding_dim)\n",
        "output, weights = simple_attention(x, x, x)\n",
        "\n",
        "print(\"Attention weights shape:\", weights.shape)  # [5, 5]\n",
        "print(\"Each word attends to all words!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Concept 2 Made Simple\n",
        "Think like a Google search for understanding sentence meaning:\n",
        "- üîç **Query:** \"What is the subject of this sentence?\"\n",
        "- üóùÔ∏è **Keys:** All words offering themselves as candidates\n",
        "- üìä **Values:** The actual meaning each word provides\n",
        "- ‚úÖ **Result:** Attention finds \"cat\" as the most relevant!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Concept 2 from a Different Angle\n",
        "Visualize this idea as a conference call where everyone talks to everyone, compared to traditional models like a telephone line."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question for Thought\n",
        "Transformers revolutionized AI by allowing parallel processing and direct connections between words.\n",
        "How might this architecture benefit tasks beyond language, like image analysis or music generation?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}