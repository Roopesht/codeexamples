{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéØ Understanding Q, K, V Vectors in Attention Mechanisms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction\n",
        "In this notebook, we will learn about the fundamental components of attention mechanisms in neural networks: Query (Q), Key (K), and Value (V) vectors. These are crucial for understanding how models like Transformers focus on different parts of data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The QKV Trinity\n",
        "**Analogy:** Like a sophisticated library system!\n",
        "- üîç **Query (Q):** \"What information am I looking for?\"\n",
        "- üóùÔ∏è **Key (K):** \"What information do I have available?\"\n",
        "- üìö **Value (V):** \"The actual information content\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The QKV Process\n",
        "Let's break down the steps involved in using Q, K, V vectors:\n",
        "1. **Create Vectors:** Transform each word into Q, K, V representations.\n",
        "2. **Calculate Similarity:** Compare Query with all Keys using dot product.\n",
        "3. **Normalize Scores:** Apply softmax to get attention weights.\n",
        "4. **Weighted Sum:** Combine Values using attention weights.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Mathematical Foundation of Attention\n",
        "**Attention Formula:**\n",
        "> Attention(Q,K,V) = softmax(QK<sup>T</sup>/‚àöd<sub>k</sub>)V\n",
        "- QK<sup>T</sup>: Query-Key similarity scores\n",
        "- ‚àöd<sub>k</sub>: Scaling factor (prevents vanishing gradients)\n",
        "- softmax: Normalizes to a probability distribution\n",
        "- V: Weighted combination of values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Real-World Example: Search Engine\n",
        "- üîç **Your search:** \"best pizza restaurants\"\n",
        "- üóùÔ∏è **Keys:** Restaurant descriptions in database\n",
        "- üìö **Values:** Full restaurant information\n",
        "- üéØ **Result:** Restaurants ranked by relevance!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Demo: Implementing QKV Attention\n",
        "Let's see a simple implementation of the attention mechanism using PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimpleAttention(nn.Module):\n",
        "    def __init__(self, embed_dim):\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        \n",
        "        # Linear transformations for Q, K, V\n",
        "        self.query = nn.Linear(embed_dim, embed_dim)\n",
        "        self.key = nn.Linear(embed_dim, embed_dim)\n",
        "        self.value = nn.Linear(embed_dim, embed_dim)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # x shape: [seq_len, embed_dim]\n",
        "        Q = self.query(x)  # Queries\n",
        "        K = self.key(x)    # Keys  \n",
        "        V = self.value(x)  # Values\n",
        "        \n",
        "        # Calculate attention scores\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1))\n",
        "        scores = scores / math.sqrt(self.embed_dim)\n",
        "        \n",
        "        # Apply softmax\n",
        "        attention_weights = F.softmax(scores, dim=-1)\n",
        "        \n",
        "        # Apply attention to values\n",
        "        output = torch.matmul(attention_weights, V)\n",
        "        \n",
        "        return output, attention_weights\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Example Usage\n",
        "Set parameters and create a sample input tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "embed_dim = 64\n",
        "seq_len = 5\n",
        "x = torch.randn(seq_len, embed_dim)\n",
        "\n",
        "attention_layer = SimpleAttention(embed_dim)\n",
        "output, weights = attention_layer(x)\n",
        "\n",
        "print(f\"Input shape: {x.shape}\")\n",
        "print(f\"Output shape: {output.shape}\")\n",
        "print(f\"Attention weights shape: {weights.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Concept Simplified ‚Äî Think of QKV like dating apps:\n",
        "- üíù **Query:** Your dating preferences (e.g., \"I like funny people\")\n",
        "- üè∑Ô∏è **Key:** Other profiles' tags (e.g., \"Funny, Smart, Kind\")\n",
        "- üë§ **Value:** Full profiles with photos and details\n",
        "- üíï **Match:** The algorithm shows profiles most similar to your Query!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Different Perspective: Whiteboard view\n",
        "Imagine Q, K, V as components of a restaurant recommendation system:\n",
        "- Query: What you want (e.g., type of cuisine)\n",
        "- Key: Restaurant features (e.g., \"Italian\", \"Vegetarian\")\n",
        "- Value: Full restaurant details (menu, photos, reviews)\n",
        "QKV vectors are the secret sauce behind effective attention!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Practical Question\n",
        "If you were building a code completion tool, what would your Query vector represent when trying to complete \"def calculate_\"?\n",
        "Think about the information the model needs to generate the next part of the code!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}