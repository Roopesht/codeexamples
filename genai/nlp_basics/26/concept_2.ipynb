{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Key Differences Between GPT, Claude, and LLaMA\n",
        "\n",
        "This notebook explains the main differences between three popular Large Language Models (LLMs): GPT, Claude, and LLaMA.\n",
        "Let's explore what makes each of them unique!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The Big Three: GPT vs Claude vs LLaMA\n",
        "\n",
        "![Three AI robots](images/three_ai_titans.png)\n",
        "\n",
        "Each has its own strengths â€” let's find out what makes them special!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¤– GPT (OpenAI)\n",
        "- **Strength:** Versatile, great at creative tasks\n",
        "- **Training:** Massive internet data\n",
        "- **Best for:** Writing, coding, general chat\n",
        "- **Access:** API-based, ChatGPT interface\n",
        "\n",
        "*The \"Swiss Army knife\" of language models!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ§  Claude (Anthropic)\n",
        "- **Strength:** Safety-focused, nuanced reasoning\n",
        "- **Training:** Constitutional AI approach\n",
        "- **Best for:** Analysis, careful reasoning, ethical tasks\n",
        "- **Access:** API and web interface\n",
        "\n",
        "*The \"thoughtful philosopher\" of AI models!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¦™ LLaMA (Meta)\n",
        "- **Strength:** Open-source, customizable\n",
        "- **Training:** Efficiency-focused approach\n",
        "- **Best for:** Research, custom applications\n",
        "- **Access:** Download and run locally\n",
        "\n",
        "*The \"open-source champion\" for developers!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Side-by-Side Comparison\n",
        "\n",
        "| Feature         | GPT            | Claude         | LLaMA          |\n",
        "|-----------------|----------------|----------------|----------------|\n",
        "| Creativity      | ğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸ      | ğŸŒŸğŸŒŸğŸŒŸğŸŒŸ       | ğŸŒŸğŸŒŸğŸŒŸğŸŒŸ       |\n",
        "| Safety          | ğŸŒŸğŸŒŸğŸŒŸğŸŒŸ       | ğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸ    | ğŸŒŸğŸŒŸğŸŒŸ         |\n",
        "| Customization   | ğŸŒŸğŸŒŸ           | ğŸŒŸğŸŒŸ           | ğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸ    |\n",
        "| Cost            | ğŸ’°ğŸ’°ğŸ’°       | ğŸ’°ğŸ’°ğŸ’°       | ğŸ’° (Free)      |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Let's Compare Them Live!\n",
        "\n",
        "ğŸ¯ **Same prompt, different models:**\n",
        "\n",
        "*(Example prompt:)*\n",
        "Explain quantum computing to a 10-year-old\n",
        "\n",
        "Watch how each model approaches this challenge differently!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Compare different LLM responses\n",
        "import openai\n",
        "import anthropic\n",
        "# assuming llama_model is defined and initialized elsewhere\n",
        "\n",
        "def compare_llms(prompt):\n",
        "    results = {}\n",
        "    \n",
        "    # GPT Response (via OpenAI API)\n",
        "    gpt_response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    results[\"GPT\"] = gpt_response.choices[0].message.content\n",
        "    \n",
        "    # Claude Response (via Anthropic API)\n",
        "    claude_response = anthropic.complete(\n",
        "        prompt=prompt,\n",
        "        model=\"claude-v1\"\n",
        "    )\n",
        "    results[\"Claude\"] = claude_response.completion\n",
        "    \n",
        "    # LLaMA Response (local model)\n",
        "    llama_response = llama_model.generate(prompt)\n",
        "    results[\"LLaMA\"] = llama_response\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Compare responses\n",
        "prompt = \"Explain quantum computing to a 10-year-old\"\n",
        "comparison = compare_llms(prompt)\n",
        "\n",
        "for model, response in comparison.items():\n",
        "    print(f\"\\n{model} says:\")\n",
        "    print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ğŸš€ **Try this in Colab:**\n",
        "[Open the LLM comparison notebook in Colab](https://colab.research.google.com/github/Roopesht/codeexamples/blob/main/genai/python_easy/7/llm_comparison.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LLM Differences Made Simple\n",
        "\n",
        "ğŸ  Think of them like different house types:\n",
        "- **GPT:** Luxury apartment - premium, full-service\n",
        "- **Claude:** Safe family home - secure, thoughtful\n",
        "- **LLaMA:** DIY kit house - customizable, you build it\n",
        "\n",
        "*Each serves different needs and preferences!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Which LLM for Which Task?\n",
        "\n",
        "![Interactive guide](llm-usecase-animation.js)\n",
        "\n",
        "*Interactive guide to choosing the right model!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LLM Selection from a Different Angle\n",
        "\n",
        "ğŸ¨ **Whiteboard Decision Tree!**\n",
        "\n",
        "Let's map out when to choose each model:\n",
        "- Budget constraints?\n",
        "- Safety requirements?\n",
        "- Customization needs?\n",
        "- Performance priorities?\n",
        "\n",
        "**Now you can pick the right LLM for any project! ğŸ¯**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quick Check: Model Selection\n",
        "\n",
        "**Each LLM has distinct strengths:** GPT for creativity, Claude for safety, LLaMA for customization.\n",
        "\n",
        "ğŸ¤” **Question:** For a medical chatbot that needs high accuracy and safety, which LLM would you choose and why?"
      ]
    }
  ]
}