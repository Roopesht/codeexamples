{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Concept 3: Generalization to Unseen Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ğŸŒ **What is Generalization?**\n",
        "\n",
        "![A model being tested on new data it has never seen before, size 800x500](images/generalization_concept.png)\n",
        "\n",
        "*\"The ultimate test of a model's true intelligence\"*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ Why Generalization Matters\n",
        "\n",
        "- ğŸŒŸ Real-world data is always \"unseen\"\n",
        "- ğŸ“Š Training accuracy â‰  Real-world performance\n",
        "- ğŸ” Prevents model from being a \"memory machine\"\n",
        "- ğŸ’¡ Key to building reliable AI systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“ˆ Factors Affecting Generalization\n",
        "\n",
        "- ğŸ“Š Training data quality and diversity\n",
        "- ğŸ¯ Model complexity vs data size\n",
        "- ğŸ”„ Feature selection and engineering\n",
        "- âš–ï¸ Regularization techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing Generalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Assuming X and y are your features and labels\n",
        "\n",
        "# Create models with different complexities\n",
        "models = {\n",
        "    'Simple': RandomForestRegressor(n_estimators=10, max_depth=3, random_state=42),\n",
        "    'Moderate': RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42),\n",
        "    'Complex': RandomForestRegressor(n_estimators=200, max_depth=None, random_state=42)\n",
        "}\n",
        "\n",
        "# Test generalization using cross-validation\n",
        "for name, model in models.items():\n",
        "    cv_scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
        "    mean_score = -cv_scores.mean()\n",
        "    std_score = cv_scores.std()\n",
        "    \n",
        "    print(f\"{name} Model:\")\n",
        "    print(f\"  CV Score: {mean_score:.3f} (+/- {std_score:.3f})\")\n",
        "    print(f\"  Generalization: {'Good' if std_score < 0.1 else 'Poor'}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[ğŸš€ Open in Colab](https://colab.research.google.com/github/Roopesht/codeexamples/blob/main/genai/python_easy/3/generalization_test.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ Generalization Success\n",
        "\n",
        "- **Good generalization:** Consistent performance across different data samples\n",
        "- **Poor generalization:** Wild performance swings on new data\n",
        "\n",
        "*ğŸ’­ Think: How would you test if your model generalizes well to completely new scenarios?*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}