{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ‚ö° Advanced: Default Parameters & *args/**kwargs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ö° Advanced Function Features\n",
        "- üîß **Default Parameters**: Provide fallback values\n",
        "- üîÑ **Keyword Arguments**: Named parameters\n",
        "- üì¶ **\\*args**: Variable number of positional arguments\n",
        "- üóÇÔ∏è **\\*\\*kwargs**: Variable number of keyword arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Default parameters\ndef create_ai_request(prompt, model=\"gpt-3.5-turbo\", temperature=0.7):\n",
        "    \"\"\"Creates AI request with sensible defaults\"\"\"\n",
        "    return {\n",
        "        \"prompt\": prompt,\n",
        "        \"model\": model,\n",
        "        \"temperature\": temperature\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# *args and **kwargs\ndef flexible_prompt(*topics, **settings):\n",
        "    \"\"\"Handles variable number of topics and settings\"\"\"\n",
        "    combined_topics = \" and \".join(topics)\n",
        "    prompt = f\"Write about {combined_topics}\"\n",
        "    if settings.get(\"style\"):\n",
        "        prompt += f\" in {settings['style']} style\"\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Usage examples\n",
        "request1 = create_ai_request(\"Explain Python\")\n",
        "request2 = create_ai_request(\"Explain Python\", model=\"gpt-4\", temperature=0.9)\n",
        "\n",
        "result1 = flexible_prompt(\"AI\", \"Machine Learning\")\n",
        "result2 = flexible_prompt(\"Python\", \"Data Science\", style=\"academic\", length=\"detailed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'prompt': 'Explain Python', 'model': 'gpt-3.5-turbo', 'temperature': 0.7}\n",
            "Write about AI and Machine Learning\n"
          ]
        }
      ],
      "source": [
        "print(request1)\n",
        "print(result1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Open in Colab\n",
        "[üöÄ Open in Colab](https://colab.research.google.com/github/Roopesht/codeexamples/blob/main/genai/python_easy/7/advanced.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì§ Output\n",
        "```python\n",
        "{'prompt': 'Explain Python', 'model': 'gpt-3.5-turbo', 'temperature': 0.7}\n",
        "Write about AI and Machine Learning\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Key Takeaway\n",
        "Advanced function features provide incredible flexibility for GenAI applications, allowing you to handle various inputs and provide sensible defaults."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}