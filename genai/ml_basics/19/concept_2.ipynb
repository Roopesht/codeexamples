{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Validation\n",
        "\n",
        "## How Do We Know Our Model is Good?\n",
        "\n",
        "In machine learning, just like in many other areas, we want to check if our models make good predictions. This notebook will introduce you to ways to measure how well your models perform, depending on the kind of problem you're solving."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üìä Model Validation: Different Problems, Different Metrics\n",
        "\n",
        "Imagine you have a dashboard that shows different scores depending on what you're measuring. Different problems need different metrics to see how good your model is! For example, predicting house prices (regression) uses different tools than classifying emails (classification)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üìà Regression Validation Metrics\n",
        "\n",
        "When we predict continuous numbers, like house prices, we use specific metrics to see how close our predictions are to the true values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### How Good Are Your Number Predictions?\n",
        "\n",
        "- üìè **MSE (Mean Squared Error):** Average of squared differences between predicted and actual values.\n",
        "- üìê **RMSE (Root Mean Squared Error):** Square root of MSE, in the same units as your target.\n",
        "- üìä **MAE (Mean Absolute Error):** Average of absolute differences.\n",
        "- üéØ **R¬≤ Score:** How much variance in the data is explained by the model. Ranges from 0 to 1; higher is better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: calculating regression metrics\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Suppose y_test are the true values and predictions are your model's predictions\n",
        "y_test = [200000, 150000, 250000, 300000]\n",
        "predictions = [210000, 140000, 260000, 310000]\n",
        "\n",
        "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(f\\\"RMSE: {rmse:.2f}\\\")\n",
        "print(f\\\"R¬≤: {r2:.3f}\\\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üè∑Ô∏è Classification Validation Metrics\n",
        "\n",
        "When predicting categories (like spam or not spam), different metrics are used to evaluate performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### How Good Are Your Category Predictions?\n",
        "\n",
        "- ‚úÖ **Accuracy:** Percentage of correct predictions.\n",
        "- üéØ **Precision:** Out of all items predicted as positive, how many were really positive?\n",
        "- üîç **Recall:** Out of all real positives, how many did the model find?\n",
        "- ‚öñÔ∏è **F1 Score:** The balance between precision and recall.\n",
        "- üìã **Confusion Matrix:** A detailed table showing true positives, false positives, true negatives, and false negatives."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: calculating classification metrics\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Simulated true labels and predictions\n",
        "y_test = [0, 1, 0, 1, 1]\n",
        "predictions = [0, 0, 0, 1, 1]\n",
        "\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f\\\"Accuracy: {accuracy:.3f}\\\")\n",
        "print(classification_report(y_test, predictions))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üí° Pro Tips for Model Improvement\n",
        "\n",
        "Boost your model's performance with these techniques:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Boosting Performance\n",
        "\n",
        "- **Regression:** Use feature scaling, Ridge/Lasso regularization, and ensemble methods.\n",
        "- **Classification:** Balance classes, use cross-validation, and tune decision thresholds.\n",
        "- **Both:** Improve features, gather more data, and tune hyperparameters for better results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Validation in Action\n",
        "\n",
        "Here's some example code to perform validation using scikit-learn:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Regression Validation\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Example data\n",
        "y_test = [200000, 150000, 250000, 300000]\n",
        "predictions = [210000, 140000, 260000, 310000]\n",
        "\n",
        "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "print(f\\\"RMSE: {rmse:.2f}, R¬≤: {r2:.3f}\\\")\n",
        "\n",
        "# Classification Validation\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "y_test = [0, 1, 0, 1, 1]\n",
        "predictions = [0, 0, 0, 1, 1]\n",
        "\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f\\\"Accuracy: {accuracy:.3f}\\\")\n",
        "print(classification_report(y_test, predictions))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üéØ Validation Wisdom\n",
        "\n",
        "Remember: \n",
        "\"A model without proper validation is like driving with your eyes closed!\"\n",
        "\n",
        "**Quick Check:**\n",
        "If your house price model has an RMSE of $50,000, is that good or bad? (Hint: it depends on the price range!)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}