{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Building and Refining Your Machine Learning Model\n",
        "\n",
        "In this notebook, we will learn how to train, test, and improve machine learning models step by step. Let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Concept 3: Training, Testing, and Improving Models\n",
        "\n",
        "- 🎯 Train/validation/test split strategy\n",
        "- 🤖 Model selection and hyperparameter tuning\n",
        "- 📊 Cross-validation techniques\n",
        "- 🔧 Overfitting and underfitting solutions\n",
        "- 📈 Performance optimization strategies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎯 Data Splitting Strategy\n",
        "\n",
        "To evaluate our model fairly, we split our dataset into three parts: training, validation, and testing.\n",
        "\n",
        "![Train Test Split Image](images/train_test_split.png)\n",
        "\n",
        "- **Training (60-80%)**: The data used for the model to learn.\n",
        "- **Validation (10-20%)**: Used to tune hyperparameters.\n",
        "- **Test (10-20%)**: Final evaluation of the model's performance on unseen data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🤖 Model Selection Process\n",
        "\n",
        "When building a machine learning model, follow these steps:\n",
        "\n",
        "1. **Start simple**: Try basic models first.\n",
        "2. **Compare algorithms**: Use different models like Logistic Regression, Random Forest, and SVM.\n",
        "3. **Tune hyperparameters**: Improve model performance by adjusting settings.\n",
        "4. **Validate results**: Use cross-validation to check how well your model performs.\n",
        "\n",
        "_💡 Remember: Complex models are not always better!_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ⚖️ Overfitting vs Underfitting\n",
        "\n",
        "Striking the right balance is crucial.\n",
        "\n",
        "![Overfitting and Underfitting Graph](images/overfitting_underfitting.png)\n",
        "\n",
        "- 🎯 **Just Right**: Good performance on new data.\n",
        "- 📈 **Overfitting**: The model memorizes training data and performs poorly on new data.\n",
        "- 📉 **Underfitting**: The model is too simple and cannot capture the data patterns.\n",
        "- 🔧 **Solutions**: Regularization, more data, and cross-validation can help."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔧 Model Training and Evaluation\n",
        "\n",
        "Let's see how to train and evaluate different models using sklearn.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Suppose X and y are your features and labels\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define models to compare\n",
        "models = {\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000)\n",
        "}\n",
        "\n",
        "# Compare models using cross-validation and evaluate on test data\n",
        "for name, model in models.items():\n",
        "    # Cross-validation scores on training data\n",
        "    cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
        "    print(f\"{name} CV Score: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})\")\n",
        "    \n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "    # Evaluate on training data\n",
        "    train_score = model.score(X_train, y_train)\n",
        "    # Evaluate on testing data\n",
        "    test_score = model.score(X_test, y_test)\n",
        "    print(f\"{name} - Train: {train_score:.3f}, Test: {test_score:.3f}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🚀 Open in Colab\n",
        "[Open this notebook in Google Colab](https://colab.research.google.com/github/Roopesht/codeexamples/blob/main/genai/python_easy/4/concept_3.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎯 Key Takeaway\n",
        "\n",
        "Great models are built through systematic experimentation and validation!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 💭 Think About It\n",
        "\n",
        "How would you know if your model is ready for production?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}