{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Tuning Challenge\n",
        "\n",
        "Welcome to the hands-on task! In this notebook, we'll explore how to train models with different complexities and analyze their performance to understand underfitting and overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ The Tuning Challenge\n",
        "\n",
        "Our mission is to train multiple models with varying complexity, compare their performance, and interpret the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Model Performance Dashboard](images/tuning_challenge.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“‹ Task Requirements\n",
        "\n",
        "- ğŸ¯ Train 5 models with different complexities\n",
        "- ğŸ“Š Use both K-Nearest Neighbors (KNN) and Decision Tree algorithms\n",
        "- ğŸ“ˆ Create visualization comparing performance\n",
        "- ğŸ” Identify which models underfit or overfit\n",
        "- ğŸ’¡ Recommend the best model configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š Expected Input/Output\n",
        "\n",
        "**Input:** Housing price dataset with features like area, bedrooms, location.\n",
        "\n",
        "**Output:** A comparison chart showing:\n",
        "- ğŸ“ˆ Training vs Test accuracy for each model\n",
        "- ğŸ¯ Identification of the best generalizing model\n",
        "- ğŸ“Š Visual plots illustrating fit quality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”§ Step-by-Step Process\n",
        "\n",
        "1. ğŸ“Š Load and prepare the dataset\n",
        "2. ğŸ”§ Create models with varying complexity\n",
        "3. ğŸ“ˆ Train and evaluate each model\n",
        "4. ğŸ“Š Generate comparison visualizations\n",
        "5. ğŸ¯ Analyze and interpret results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task Code Structure\n",
        "\n",
        "Below is the outline of the code you'll implement:\n",
        "\n",
        "```python\n",
        "# Task: Model Complexity Analysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load dataset\n",
        "housing = fetch_california_housing()\n",
        "X, y = housing.data, housing.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create models with different complexities\n",
        "models = {\n",
        "    'KNN_1': KNeighborsRegressor(n_neighbors=1),\n",
        "    'KNN_5': KNeighborsRegressor(n_neighbors=5),\n",
        "    'KNN_20': KNeighborsRegressor(n_neighbors=20),\n",
        "    'Tree_Deep': DecisionTreeRegressor(max_depth=20),\n",
        "    'Tree_Shallow': DecisionTreeRegressor(max_depth=5)\n",
        "}\n",
        "\n",
        "# Train and evaluate each model\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "    # Predict on training data\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    # Predict on test data\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    # Calculate metrics\n",
        "    train_rmse = mean_squared_error(y_train, y_train_pred, squared=False)\n",
        "    test_rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
        "    train_r2 = r2_score(y_train, y_train_pred)\n",
        "    test_r2 = r2_score(y_test, y_test_pred)\n",
        "    # Store results\n",
        "    results[name] = {\n",
        "        'train_rmse': train_rmse,\n",
        "        'test_rmse': test_rmse,\n",
        "        'train_r2': train_r2,\n",
        "        'test_r2': test_r2\n",
        "    }\n",
        "\n",
        "# Visualization and analysis will be added in subsequent steps\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ğŸš€ You can also open this notebook in Colab for interactive exploration:\n",
        "\n",
        "[Open in Colab](https://colab.research.google.com/github/Roopesht/codeexamples/blob/main/genai/python_easy/3/tuning_challenge.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ Success Criteria\n",
        "\n",
        "- âœ… Can identify overfitting vs underfitting patterns\n",
        "- âœ… Understand the relationship between model complexity and performance\n",
        "- âœ… Can recommend the optimal model based on generalization"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}