{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Tuning Challenge\n",
        "\n",
        "Welcome to the hands-on task! In this notebook, we'll explore how to train models with different complexities and analyze their performance to understand underfitting and overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎯 The Tuning Challenge\n",
        "\n",
        "Our mission is to train multiple models with varying complexity, compare their performance, and interpret the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Model Performance Dashboard](images/tuning_challenge.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📋 Task Requirements\n",
        "\n",
        "- 🎯 Train 5 models with different complexities\n",
        "- 📊 Use both K-Nearest Neighbors (KNN) and Decision Tree algorithms\n",
        "- 📈 Create visualization comparing performance\n",
        "- 🔍 Identify which models underfit or overfit\n",
        "- 💡 Recommend the best model configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📊 Expected Input/Output\n",
        "\n",
        "**Input:** Housing price dataset with features like area, bedrooms, location.\n",
        "\n",
        "**Output:** A comparison chart showing:\n",
        "- 📈 Training vs Test accuracy for each model\n",
        "- 🎯 Identification of the best generalizing model\n",
        "- 📊 Visual plots illustrating fit quality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔧 Step-by-Step Process\n",
        "\n",
        "1. 📊 Load and prepare the dataset\n",
        "2. 🔧 Create models with varying complexity\n",
        "3. 📈 Train and evaluate each model\n",
        "4. 📊 Generate comparison visualizations\n",
        "5. 🎯 Analyze and interpret results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task Code Structure\n",
        "\n",
        "Below is the outline of the code you'll implement:\n",
        "\n",
        "```python\n",
        "# Task: Model Complexity Analysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load dataset\n",
        "housing = fetch_california_housing()\n",
        "X, y = housing.data, housing.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create models with different complexities\n",
        "models = {\n",
        "    'KNN_1': KNeighborsRegressor(n_neighbors=1),\n",
        "    'KNN_5': KNeighborsRegressor(n_neighbors=5),\n",
        "    'KNN_20': KNeighborsRegressor(n_neighbors=20),\n",
        "    'Tree_Deep': DecisionTreeRegressor(max_depth=20),\n",
        "    'Tree_Shallow': DecisionTreeRegressor(max_depth=5)\n",
        "}\n",
        "\n",
        "# Train and evaluate each model\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "    # Predict on training data\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    # Predict on test data\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    # Calculate metrics\n",
        "    train_rmse = mean_squared_error(y_train, y_train_pred, squared=False)\n",
        "    test_rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
        "    train_r2 = r2_score(y_train, y_train_pred)\n",
        "    test_r2 = r2_score(y_test, y_test_pred)\n",
        "    # Store results\n",
        "    results[name] = {\n",
        "        'train_rmse': train_rmse,\n",
        "        'test_rmse': test_rmse,\n",
        "        'train_r2': train_r2,\n",
        "        'test_r2': test_r2\n",
        "    }\n",
        "\n",
        "# Visualization and analysis will be added in subsequent steps\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "🚀 You can also open this notebook in Colab for interactive exploration:\n",
        "\n",
        "[Open in Colab](https://colab.research.google.com/github/Roopesht/codeexamples/blob/main/genai/python_easy/3/tuning_challenge.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎯 Success Criteria\n",
        "\n",
        "- ✅ Can identify overfitting vs underfitting patterns\n",
        "- ✅ Understand the relationship between model complexity and performance\n",
        "- ✅ Can recommend the optimal model based on generalization"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}