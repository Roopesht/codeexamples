{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Understanding Bias and Variance\n",
        "\n",
        "This notebook introduces the concepts of Bias and Variance in machine learning, helping you understand the fundamental tradeoff in model performance.\n",
        "\n",
        "![Dartboard showing bias and variance](images/bias_variance_dartboard.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What is Bias and Variance?\n",
        "\n",
        "Bias and Variance are two types of error that affect the performance of machine learning models.\n",
        "\n",
        "Bias measures errors due to overly simplistic assumptions in the model. High bias can lead to underfitting, where the model fails to capture the true pattern.\n",
        "\n",
        "Variance measures errors due to the model's sensitivity to small fluctuations in the training data. High variance can cause overfitting, where the model captures noise instead of the underlying pattern."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bias Explained\n",
        "\n",
        "- üéØ Error due to oversimplified assumptions\n",
        "- üìâ Model consistently misses the true pattern\n",
        "- üîç High bias = underfitting\n",
        "- üí° Example: Using linear model for curved data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Variance Explained\n",
        "\n",
        "- üé≤ Error due to sensitivity to small data changes\n",
        "- üìä Model predictions vary widely with different datasets\n",
        "- üîç High variance = overfitting\n",
        "- üí° Example: Very deep decision tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizing Bias and Variance with Code\n",
        "\n",
        "Below is an example code that demonstrates high bias (underfitting) and high variance (overfitting) using simple models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Generate sample data\n",
        "np.random.seed(42)\n",
        "X = np.linspace(0, 1, 100).reshape(-1, 1)\n",
        "y = 0.5 * X.ravel() + 0.3 * np.sin(15 * X.ravel()) + np.random.normal(0, 0.1, X.shape[0])\n",
        "\n",
        "# High bias model (underfitting)\n",
        "linear_model = LinearRegression()\n",
        "linear_model.fit(X, y)\n",
        "\n",
        "# High variance model (overfitting)\n",
        "tree_model = DecisionTreeRegressor(max_depth=20)\n",
        "tree_model.fit(X, y)\n",
        "\n",
        "print(\"Linear Model (High Bias):\", linear_model.score(X, y))\n",
        "print(\"Deep Tree (High Variance):\", tree_model.score(X, y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Takeaway\n",
        "\n",
        "- üéØ **The Goal:** Find the sweet spot between bias and variance for optimal model performance.\n",
        "\n",
        "üí≠ How would you explain bias vs variance to a friend using a real-world analogy?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}