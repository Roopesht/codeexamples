{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Introduction to Cross-Validation\n",
        "In this notebook, we will learn about Cross-Validation, a technique to evaluate how well a machine learning model performs.\n",
        "Let's explore why we need it and how it works."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why is Single Train/Test Split Sometimes Misleading?\n",
        "Here's a simple diagram to illustrate the problem:\n",
        "![Single Split Problem](images/single_split_problem.png)\n",
        "- **Randomness:** The split might be lucky or unlucky.\n",
        "- **Bias:** Performance depends on which data is in the test set.\n",
        "- **Question:** Is 95% accuracy truly good or just a lucky split?\n",
        "- **Solution:** Use multiple splits to get a better estimate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## K-Fold Cross-Validation Process\n",
        "The most common method is **K-Fold Cross-Validation**.\n",
        "Here's how it works:\n",
        "1. **Split:** Divide your data into K equal parts (called folds).\n",
        "2. **Iterate:** Use K-1 folds to train the model and 1 fold to test.\n",
        "3. **Repeat:** Do this K times, each time with a different fold as the test set.\n",
        "4. **Average:** Calculate the average performance across all K runs.\n",
        "This gives a more reliable estimate of your model's performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Benefits of Cross-Validation\n",
        "- **Reliability:** Reduces the chance that a lucky split will give a misleading performance.\n",
        "- **Confidence:** Shows the range of model performance, not just a single number.\n",
        "- **Detection:** Helps identify if the model is overfitting.\n",
        "- **Efficiency:** Uses all data for both training and testing.\n",
        "‚ö†Ô∏è Note: Cross-Validation takes more computation time but provides better insights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example: Cross-Validation in Python\n",
        "Let's see how to perform cross-validation using scikit-learn:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "import numpy as np\n",
        "\n",
        "# Load data\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Create model\n",
        "model = KNeighborsClassifier()\n",
        "\n",
        "# 5-fold cross-validation\n",
        "cv_scores = cross_val_score(model, X, y, cv=5)\n",
        "\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(f\"Mean accuracy: {cv_scores.mean():.3f}\")\n",
        "print(f\"Standard deviation: {cv_scores.std():.3f}\")\n",
        "print(f\"95% confidence interval: {cv_scores.mean():.3f} ¬± {1.96 * cv_scores.std():.3f}\")\n",
        "\n",
        "# More detailed cross-validation\n",
        "cv_results = cross_validate(model, X, y, cv=5, \n",
        "                           scoring=['accuracy', 'precision_macro', 'recall_macro'])\n",
        "print(\"\\nDetailed results:\")\n",
        "for metric, scores in cv_results.items():\n",
        "    if metric.startswith('test_'):\n",
        "        print(f\"{metric}: {scores.mean():.3f} ¬± {scores.std():.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üëâ [Open in Colab](https://colab.research.google.com/github/Roopesht/codeexamples/blob/main/genai/python_easy/2/concept_4.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Takeaway\n",
        "Cross-validation gives you confidence in your model's true performance!\n",
        "ü§î **Question:** Why might a model with 90% ¬± 2% accuracy be better than one with 95% ¬± 15% accuracy?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}