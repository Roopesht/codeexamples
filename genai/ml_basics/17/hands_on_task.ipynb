{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Judge Challenge\n",
        "Welcome to the machine learning model comparison tutorial! In this notebook, we'll compare K-Nearest Neighbors (KNN) and Decision Tree classifiers on the wine dataset.\n",
        "Let's learn how to load data, train models, evaluate their performance, and decide which one performs better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load and Explore the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_wine\n",
        "import pandas as pd\n",
        "\n",
        "# Load the wine dataset\n",
        "wine = load_wine()\n",
        "X = wine.data\n",
        "y = wine.target\n",
        "\n",
        "# Convert to DataFrame for easier exploration\n",
        "df = pd.DataFrame(X, columns=wine.feature_names)\n",
        "df['target'] = y\n",
        "\n",
        "# Display first few rows\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dataset contains 178 samples with 13 features each, labeled into 3 different wine classes.\n",
        "Next, let's split the data into training and testing sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {X_train.shape[0]}\")\n",
        "print(f\"Testing samples: {X_test.shape[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Train K-Nearest Neighbors (KNN) and Decision Tree models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize models\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train models\n",
        "knn.fit(X_train, y_train)\n",
        "dt.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Evaluate the models with classification metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Predict on test data\n",
        "knn_pred = knn.predict(X_test)\n",
        "dt_pred = dt.predict(X_test)\n",
        "\n",
        "# Define a function to evaluate a model\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    report = classification_report(y_true, y_pred, output_dict=True)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='macro')\n",
        "    recall = recall_score(y_true, y_pred, average='macro')\n",
        "    f1 = f1_score(y_true, y_pred, average='macro')\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "        \"report\": report\n",
        "    }\n",
        "\n",
        "# Evaluate KNN\n",
        "knn_results = evaluate_model(y_test, knn_pred)\n",
        "# Evaluate Decision Tree\n",
        "dt_results = evaluate_model(y_test, dt_pred)\n",
        "\n",
        "# Display results\n",
        "print(\"=== KNN Performance ===\")\n",
        "print(f\"Accuracy: {knn_results['accuracy']:.3f}\")\n",
        "print(f\"Precision: {knn_results['precision']:.3f}\")\n",
        "print(f\"Recall: {knn_results['recall']:.3f}\")\n",
        "print(f\"F1 Score: {knn_results['f1']:.3f}\")\n",
        "\n",
        "print(\"\\n=== Decision Tree Performance ===\")\n",
        "print(f\"Accuracy: {dt_results['accuracy']:.3f}\")\n",
        "print(f\"Precision: {dt_results['precision']:.3f}\")\n",
        "print(f\"Recall: {dt_results['recall']:.3f}\")\n",
        "print(f\"F1 Score: {dt_results['f1']:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Visualize confusion matrices for comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Function to plot confusion matrix\n",
        "def plot_confusion(matrix, title):\n",
        "    plt.figure(figsize=(6,4))\n",
        "    sns.heatmap(matrix, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "# Plot for KNN\n",
        "cm_knn = confusion_matrix(y_test, knn_pred)\n",
        "plot_confusion(cm_knn, 'Confusion Matrix for KNN')\n",
        "\n",
        "# Plot for Decision Tree\n",
        "cm_dt = confusion_matrix(y_test, dt_pred)\n",
        "plot_confusion(cm_dt, 'Confusion Matrix for Decision Tree')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Perform cross-validation to get an overall performance perspective"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Cross-validation scores for KNN\n",
        "knn_cv_scores = cross_val_score(knn, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "# Cross-validation scores for Decision Tree\n",
        "dt_cv_scores = cross_val_score(dt, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "# Display mean and std\n",
        "print(f\"KNN Cross-Validation Accuracy: {knn_cv_scores.mean():.3f} ¬± {knn_cv_scores.std():.3f}\")\n",
        "print(f\"Decision Tree Cross-Validation Accuracy: {dt_cv_scores.mean():.3f} ¬± {dt_cv_scores.std():.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final Step: Judge's Verdict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on the evaluation metrics and cross-validation results, the model with the better overall performance is the clear winner.\n",
        "\n",
        "### Example verdict:\n",
        "üèÜ **Winner: KNN** because it achieved higher accuracy and F1 score on the test set, and maintained solid performance during cross-validation.\n",
        "\n",
        "Great job comparing models objectively!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}