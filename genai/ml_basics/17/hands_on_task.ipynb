{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Judge Challenge\n",
        "Welcome to this beginner-friendly tutorial on comparing machine learning models!\n",
        "We'll learn how to evaluate two models — K-Nearest Neighbors (KNN) and Decision Tree — using the breast cancer dataset.\n",
        "\n",
        "Let's dive in!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load & Split the Data\n",
        "First, we'll load the breast cancer dataset from sklearn and split it into training and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# Split into training and testing data (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data.data, data.target, test_size=0.2, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Create and Train Models\n",
        "We'll create two models — KNN and Decision Tree — and train them on the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Initialize models\n",
        "models = {\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=42)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Cross-Validation & Evaluation\n",
        "We'll evaluate the models using 5-fold cross-validation and then test their performance on the unseen test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Prepare a dictionary to store results\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"Training and evaluating {name}...\")\n",
        "    # Perform 5-fold cross-validation on training data\n",
        "    cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
        "    cv_mean = cv_scores.mean()\n",
        "    cv_std = cv_scores.std()\n",
        "\n",
        "    # Train the model on full training data\n",
        "    model.fit(X_train, y_train)\n",
        "    # Predict on test data\n",
        "    y_pred = model.predict(X_test)\n",
        "    # Calculate evaluation metrics\n",
        "    test_accuracy = accuracy_score(y_test, y_pred)\n",
        "    test_precision = precision_score(y_test, y_pred)\n",
        "    test_recall = recall_score(y_test, y_pred)\n",
        "    test_f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    # Store the results\n",
        "    results[name] = {\n",
        "        'cv_mean': cv_mean,\n",
        "        'cv_std': cv_std,\n",
        "        'test_accuracy': test_accuracy,\n",
        "        'test_precision': test_precision,\n",
        "        'test_recall': test_recall,\n",
        "        'test_f1': test_f1\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Display Results & Decide the Winner\n",
        "Let's compare the models based on the evaluation metrics and decide which one performs better overall."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "print(\"MODEL COMPARISON RESULTS:\")\n",
        "print(\"=\"*25)\n",
        "for name, res in results.items():\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"- CV Accuracy: {res['cv_mean']:.3f} ± {res['cv_std']:.3f}\")\n",
        "    print(f\"- Test Accuracy: {res['test_accuracy']:.3f}\")\n",
        "    print(f\"- Test Precision: {res['test_precision']:.3f}\")\n",
        "    print(f\"- Test Recall: {res['test_recall']:.3f}\")\n",
        "    print(f\"- Test F1: {res['test_f1']:.3f}\")\n",
        "\n",
        "# Decide the winner based on test accuracy and stability\n",
        "knn = results['KNN']\n",
        "dt = results['Decision Tree']\n",
        "\n",
        "if knn['test_accuracy'] > dt['test_accuracy']:\n",
        "    winner = 'KNN Classifier'\n",
        "    reason = 'Higher overall accuracy and more stable performance'\n",
        "elif dt['test_accuracy'] > knn['test_accuracy']:\n",
        "    winner = 'Decision Tree'\n",
        "    reason = 'Higher overall accuracy'\n",
        "else:\n",
        "    winner = 'Both models perform similarly'\n",
        "    reason = 'Comparable accuracy, consider other metrics'\n",
        "\n",
        "print(f\"\\nWINNER: {winner}\")\n",
        "print(f\"REASON: {reason}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final Thoughts\n",
        "In this exercise, you learned how to: \n",
        "- Load and split data for training and testing\n",
        "- Create and evaluate multiple models\n",
        "- Use cross-validation for fair comparison\n",
        "- Consider various metrics to judge model performance\n",
        "\n",
        "Remember: Good data scientists judge models fairly by looking at multiple evaluation aspects!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  }
}