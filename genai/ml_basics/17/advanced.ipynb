{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Advanced: Hands-on with sklearn Tools\n",
        "\n",
        "In this notebook, we will explore some advanced tools in scikit-learn for model evaluation and selection. We will learn how to perform cross-validation, generate detailed classification reports, and understand the complete evaluation workflow. These techniques help you build reliable machine learning models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cross-validation with `cross_val_score()`\n",
        "\n",
        "Cross-validation is a technique to evaluate how well your model generalizes to unseen data. It involves splitting the data into multiple parts, training and testing the model on different splits to get a more reliable estimate of performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_wine\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Dataset\n",
        "\n",
        "We will use the `load_wine` dataset, which is a classic dataset for classification tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "wine = load_wine()\n",
        "X, y = wine.data, wine.target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Initial train/test split\n",
        "\n",
        "Splitting the data into training and testing sets prepares us for evaluating the model's performance later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Train the model\n",
        "\n",
        "Using a Random Forest classifier, we train on the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize and train the model\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Cross-validation on training data\n",
        "\n",
        "We perform 5-fold cross-validation to estimate the model's performance more reliably."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform cross-validation\n",
        "cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
        "print(f\"CV Score: {cv_scores.mean():.3f} ¬± {cv_scores.std():.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Final evaluation on test set\n",
        "\n",
        "We evaluate the trained model on the unseen test data and generate a classification report to see detailed metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\nFinal Test Results:\")\n",
        "print(classification_report(y_test, y_pred, target_names=wine.target_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Confusion matrix\n",
        "\n",
        "The confusion matrix provides a detailed breakdown of predictions versus true labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pro Tips for Model Evaluation\n",
        "\n",
        "- üéØ **Stratify:** Use stratified splits for imbalanced data\n",
        "- üî¢ **Random State:** Set random_state for reproducible results\n",
        "- üìä **Multiple Metrics:** Never rely on accuracy alone\n",
        "- üîÑ **Cross-Validation First:** Use CV for model selection, final test for reporting\n",
        "- ‚ö†Ô∏è **Data Leakage:** Never let test data influence training"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}