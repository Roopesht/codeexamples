{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Understanding Underfitting and Overfitting in Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Underfitting vs Overfitting - The Goldilocks Problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Three bears representing underfitting (too simple), overfitting (too complex), and just right models with corresponding data fit curves. Size 800x600](images/goldilocks_models.png)",
        "\n\n*Just like Goldilocks, we need our model to be \"just right\"!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìâ Underfitting: When Your Model is Too Simple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Symptoms:** Poor performance on both training AND test data",
        "- **Cause:** Model is too simple to capture underlying patterns",
        "- **Example:** Using linear regression for clearly non-linear data",
        "- **Signs:** High bias, low variance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Scatter plot showing curved data with a straight line poorly fitting through it. Size 600x400](images/underfitting_example.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Overfitting: When Your Model Memorizes Instead of Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Symptoms:** Great training performance, poor test performance",
        "- **Cause:** Model is too complex, captures noise as patterns",
        "- **Example:** Decision tree with 100 levels for simple data",
        "- **Signs:** Low bias, high variance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Scatter plot showing a very wavy line that passes through every training point but would poorly predict new data. Size 600x400](images/overfitting_example.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚öñÔ∏è Visual Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Three side-by-side plots showing underfitting (straight line), good fit (smooth curve), and overfitting (jagged line through all points). Size 900x400](images/fitting_comparison.png)",
        "\n\n**Training Accuracy vs Test Accuracy:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- üî¥ Underfitting: Both low",
        "- üü¢ Good fit: Both high and similar",
        "- üî¥ Overfitting: Training high, test low"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üíª Code Example: Demonstrating Over/Underfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Generate some non-linear data\n",
        "np.random.seed(0)\n",
        "X = np.sort(np.random.rand(100, 1) * 10, axis=0)\n",
        "y = np.sin(X).ravel() + np.random.randn(100) * 0.2\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create polynomial degrees to test\n",
        "degrees = [1, 2, 5, 15]  # 1=underfit, 2=good, 5=OK, 15=overfit\n",
        "\n",
        "for degree in degrees:\n",
        "    # Create polynomial pipeline\n",
        "    poly_model = Pipeline([\n",
        "        ('poly', PolynomialFeatures(degree=degree)),\n",
        "        ('linear', LinearRegression())\n",
        "    ])\n",
        "    \n",
        "    # Fit and evaluate\n",
        "    poly_model.fit(X_train, y_train)\n",
        "    train_score = poly_model.score(X_train, y_train)\n",
        "    test_score = poly_model.score(X_test, y_test)\n",
        "    \n",
        "    print(f\"Degree {degree}: Train={train_score:.3f}, Test={test_score:.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}