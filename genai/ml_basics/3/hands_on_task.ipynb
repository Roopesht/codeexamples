{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hands-on Model Tuning Challenge\n",
        "\n",
        "In this notebook, we will explore how to tune machine learning models for better performance.\n",
        "We'll work with regression models on housing price data and visualize how different complexity levels affect performance.\n",
        "\n",
        "Let's dive in!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load housing data\n",
        "housing = fetch_california_housing()\n",
        "X = housing.data\n",
        "y = housing.target\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features for better model performance\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Model Tuning Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "from sklearn.model_selection import validation_curve\n",
        "\n",
        "def tune_model(model, param_name, param_range, X, y):\n",
        "    \"\"\"Tune a model parameter and return validation curve data\"\"\"\n",
        "    train_scores, val_scores = validation_curve(\n",
        "        model,\n",
        "        X, y,\n",
        "        param_name=param_name,\n",
        "        param_range=param_range,\n",
        "        cv=5,\n",
        "        scoring='neg_mean_squared_error'\n",
        "    )\n",
        "    # Convert scores to positive MSE\n",
        "    train_scores_mean = -train_scores.mean(axis=1)\n",
        "    val_scores_mean = -val_scores.mean(axis=1)\n",
        "    return train_scores_mean, val_scores_mean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Visualization Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_validation_curve(param_range, train_scores, val_scores, title):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(param_range, train_scores, label='Training Error')\n",
        "    plt.plot(param_range, val_scores, label='Validation Error')\n",
        "    plt.xlabel('Parameter Value')\n",
        "    plt.ylabel('Mean Squared Error')\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Model Tuning and Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "models_to_tune = {\n",
        "    'Decision Tree': (DecisionTreeRegressor(), 'max_depth', range(1, 21)),\n",
        "    'Random Forest': (RandomForestRegressor(), 'n_estimators', range(10, 201, 20)),\n",
        "    'KNN': (KNeighborsRegressor(), 'n_neighbors', range(1, 51, 2))\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for model_name, (model, param_name, param_range) in models_to_tune.items():\n",
        "    print(f\"Tuning {model_name}...\")\n",
        "    train_scores, val_scores = tune_model(model, param_name, list(param_range), X_train, y_train)\n",
        "    results[model_name] = {\n",
        "        'param_range': list(param_range),\n",
        "        'train_scores': train_scores,\n",
        "        'val_scores': val_scores\n",
        "    }\n",
        "    plot_validation_curve(list(param_range), train_scores, val_scores, f\"Validation Curve for {model_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Analyze Results\n",
        "\n",
        "Based on the validation curves, identify the optimal parameter values for each model and observe regions of overfitting or underfitting.\n",
        "\n",
        "This visual analysis helps in choosing the best model and parameter setting for our dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "Congratulations! You've just learned how to tune hyperparameters of different models and visualize their performance.\n",
        "Different models have different optimal complexity levels, and validation curves help us identify these effectively.\n",
        "Remember, the best model choice depends on your specific dataset and problem!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}