{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Complexity Tuning\n",
        "\n",
        "In this notebook, we will learn how to find the best model complexity for our decision tree classifier. This process helps us achieve a good balance between underfitting and overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸš€ Introduction to Model Complexity Tuning\n",
        "\n",
        "When building machine learning models, choosing the right complexity (like the depth of a decision tree) is crucial. If the model is too simple, it won't capture important patterns (underfitting). If it's too complex, it may memorize the training data and not perform well on new data (overfitting)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŽ¯ Strategy for Tuning Model Complexity\n",
        "\n",
        "- **Start Simple:** Begin with a simple model (low complexity)\n",
        "- **Gradually Increase:** Make the model more complex step by step\n",
        "- **Monitor Performance:** Check how well the model does on training and validation data\n",
        "- **Find the Sweet Spot:** Select the complexity that gives the best validation performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ’» Interactive Model Tuning\n",
        "\n",
        "Below is a Python code example that analyzes how model accuracy changes with different tree depths. You can run this code to see the effect of complexity on performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load example dataset and split into training and validation sets\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interactive model complexity analysis\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "def analyze_complexity(max_depths):\n",
        "    train_scores = []\n",
        "    val_scores = []\n",
        "    \n",
        "    for depth in max_depths:\n",
        "        model = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
        "        \n",
        "        # Cross-validation scores\n",
        "        train_score = cross_val_score(model, X_train, y_train, cv=5).mean()\n",
        "        val_score = cross_val_score(model, X_val, y_val, cv=5).mean()\n",
        "        \n",
        "        train_scores.append(train_score)\n",
        "        val_scores.append(val_score)\n",
        "        \n",
        "        print(f\"Depth {depth}: Train={train_score:.3f}, Val={val_score:.3f}\")\n",
        "    \n",
        "    return train_scores, val_scores\n",
        "\n",
        "# Test different complexities\n",
        "depths = range(1, 15)\n",
        "train_scores, val_scores = analyze_complexity(depths)\n",
        "\n",
        "# Find optimal complexity\n",
        "optimal_depth = depths[np.argmax(val_scores)]\n",
        "print(f\"\\nðŸŽ¯ Optimal Depth: {optimal_depth}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”— Open in Colab\n",
        "\n",
        "You can run this notebook interactively in Google Colab by clicking the link below:\n",
        "\n",
        "[ðŸš€ Open in Colab](https://colab.research.google.com/github/Roopesht/codeexamples/blob/main/genai/python_easy/3/complexity_tuning.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŽ¯ Insights on Model Tuning\n",
        "\n",
        "- **Training score** tends to improve as complexity increases.\n",
        "- **Validation score** improves initially, then starts to degrade after a certain point.\n",
        "- The **best complexity** is where the validation score peaks.\n",
        "- A large gap between training and validation scores indicates overfitting.\n",
        "\n",
        "This process is fundamental in hyperparameter tuning to build more robust models."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}